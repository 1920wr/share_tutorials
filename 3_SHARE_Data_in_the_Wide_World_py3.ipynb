{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHARE Data in the Wide World\n",
    "\n",
    "This notebook will focus on how to export SHARE data into different formats, and how to query SHARE for specific information from your institution, say from a list of names or from a list of emails or ORCIDs that act as reseearcher identifiers.\n",
    "\n",
    "\n",
    "## Exporting a DataFrame to csv and Excel\n",
    "\n",
    "When doing an aggregation on SHARE data, it might be beneficial to export the data to a format that is easier to widely distribute, such as a csv file or and Excel file.\n",
    "\n",
    "First, we'll do a SHARE aggregation query for documents from each source that have a description, turn it into a pandas DataFrame, and export the data into both csv and Excel formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sharepa import ShareSearch\n",
    "from sharepa.helpers import pretty_print\n",
    "\n",
    "description_search = ShareSearch()\n",
    "\n",
    "description_search = description_search.query(\n",
    "    'exists', # Type of query, will accept a lucene query string\n",
    "    field='description', # This lucene query string will find all documents that don't have a description\n",
    ")\n",
    "\n",
    "description_search.aggs.bucket(\n",
    "    'sources',  # Every aggregation needs a name\n",
    "    'significant_terms',  # There are many kinds of aggregations\n",
    "    field='sources',  # We store the source of a document in its type, so this will aggregate by source\n",
    "    min_doc_count=0,\n",
    "    percentage={}, # Will make the score value the percentage of all results (doc_count/bg_count)\n",
    "    size=0\n",
    ")\n",
    "\n",
    "description_results = description_search.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bg_count</th>\n",
       "      <th>doc_count</th>\n",
       "      <th>score</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>providers.gov.nist</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providers.gov.scitech</th>\n",
       "      <td>1447</td>\n",
       "      <td>947</td>\n",
       "      <td>0.654457</td>\n",
       "      <td>65.445750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providers.au.uow</th>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providers.org.arxiv.oai</th>\n",
       "      <td>17547</td>\n",
       "      <td>2093</td>\n",
       "      <td>0.119280</td>\n",
       "      <td>11.927965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providers.edu.asu</th>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>7.462687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providers.be.ghent</th>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>4.109589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providers.org.crossref</th>\n",
       "      <td>10962</td>\n",
       "      <td>112</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>1.021711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providers.org.datacite</th>\n",
       "      <td>1183834</td>\n",
       "      <td>5322</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.449556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bg_count  doc_count     score     percent\n",
       "key                                                               \n",
       "providers.gov.nist              3          3  1.000000  100.000000\n",
       "providers.gov.scitech        1447        947  0.654457   65.445750\n",
       "providers.au.uow               60         15  0.250000   25.000000\n",
       "providers.org.arxiv.oai     17547       2093  0.119280   11.927965\n",
       "providers.edu.asu              67          5  0.074627    7.462687\n",
       "providers.be.ghent             73          3  0.041096    4.109589\n",
       "providers.org.crossref      10962        112  0.010217    1.021711\n",
       "providers.org.datacite    1183834       5322  0.004496    0.449556"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_dataframe = pd.DataFrame(description_results.aggregations.sources.to_dict()['buckets'])\n",
    "\n",
    "# We will add our own \"percent\" column to make things clearer\n",
    "description_dataframe['percent'] = (description_dataframe['score'] * 100)\n",
    "\n",
    "# Let's set the source name as the index, and then drop the old column\n",
    "description_dataframe = description_dataframe.set_index(description_dataframe['key'])\n",
    "description_dataframe = description_dataframe.drop('key', 1)\n",
    "\n",
    "# Finally, we'll show the results!\n",
    "description_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export this pandas dataframe to a csv file, and to an excel file.\n",
    "\n",
    "The next cell will work when running locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: Uncomment the following lines if running locally:\n",
    "\n",
    "# description_dataframe.to_csv('SHARE_Counts_with_Descriptions.csv')\n",
    "# description_dataframe.to_excel('SHARE_Counts_with_Descriptions.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with outside data\n",
    "\n",
    "Let's say we had a list of names of researchers that were from a particular University. We're interested in seeing if their full names appear in any sources across the SHARE data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"Susan Jones\", \"Ravi Patel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 documents with contributors who have any of those names.\n",
      "Here are the first 10:\n",
      "---------\n",
      "Sequence alignments for three motifs shared by proteins in the cohesion network -- with contributors ['John Sgouros', 'Susan Jones']\n",
      "Formulation, optimization and characterization of cationic polymeric nanoparticles of mast cell stabilizing agent using the Boxâ€“Behnken experimental design -- with contributors ['Chintan Dalwadi', 'Ravi Patel R.', 'Balaram Gajra']\n",
      "Can 13C stable isotope analysis uncover essential amino acid provisioning by termite-associated gut microbes -- with contributors ['Zakee Sabree', 'Susan Jones', 'Paul Ayayee']\n",
      "Effect of disturbance on species richness (), equitability (), and abundance (log ) of ants in pitfall traps (2000, 2002, and 2003) -- with contributors ['Harold Balbach', 'David Kovacic A.', 'John Zak C.', 'John Emlen M.', 'D. Freeman Carl', 'Jeffrey Duda J.', 'Anthony Krzysik J.', 'Kerri Wrinn', 'Susan Jones', 'Hoyt Hughie H.']\n",
      "Effect of disturbance on species richness (), equitability (), and abundance (log ) of ants in sweep net samples (2000, 2001, and 2002) -- with contributors ['Harold Balbach', 'David Kovacic A.', 'John Zak C.', 'John Emlen M.', 'D. Freeman Carl', 'Jeffrey Duda J.', 'Anthony Krzysik J.', 'Kerri Wrinn', 'Susan Jones', 'Hoyt Hughie H.']\n"
     ]
    }
   ],
   "source": [
    "name_search = ShareSearch()\n",
    "\n",
    "for name in names:\n",
    "    name_search = name_search.query(\n",
    "        {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"contributors.full_name\": {\n",
    "                                \"query\": name, \n",
    "                                \"operator\": \"and\",\n",
    "                                \"type\" : \"phrase\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "name_results = name_search.execute()\n",
    "\n",
    "print('There are {} documents with contributors who have any of those names.'.format(name_search.count()))\n",
    "print('Here are the first 10:')\n",
    "print('---------')\n",
    "# name_results\n",
    "for result in name_results:\n",
    "    print(\n",
    "        '{} -- with contributors {}'.format(\n",
    "            result.title,\n",
    "            [contributor.full_name for contributor in result.contributors]\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were interested to see an analysis of what sources these names came from, we can add an aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_count</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>providers.org.datacite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_count                     key\n",
       "0          5  providers.org.datacite"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_search.aggs.bucket(\n",
    "    'sources',  # Every aggregation needs a name\n",
    "    'terms',  # There are many kinds of aggregations, terms is a pretty useful one though\n",
    "    field='sources',  # We store the source of a document in its type, so this will aggregate by source\n",
    "    size=0,  # These are just to make sure we get numbers for all the sources, to make it easier to combine graphs\n",
    "    min_doc_count=1\n",
    ")\n",
    "\n",
    "name_results = name_search.execute()\n",
    "\n",
    "pd.DataFrame(name_results.aggregations.sources.to_dict()['buckets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
